---
title: "Report"
author: "Silvia Ferrer and Ignacio Lloret"
date: "2023-11-27"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(readr)
library(tidyverse)
library(DataExplorer)
library(dplyr)
library(mice)
library(chemometrics)
library(car)
library(effects)
library(FactoMineR)
library(caret)
library(Metrics)

# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

df1 <- read.csv("../data/data2.txt")
#df1 <- read.csv("../data/data.xls")


df1 %>% glimpse

```

# Data Preparation
## Missing data and Errors
Firstly, we removed possible duplicates from the dataset using the distinct function. 
Then, we factorized the variable SeniorCitizen, as it only has two categories. 
We then excluded the customerID variable since it is a unique categorical identifier that is not useful for the model, and analyzing its data distribution does not provide meaningful insights.

Checking the missing data in the dataset and which variables have NAâ€™s we can see that the ones with missing values is TotalCharges. Investigating the observations with missing values to understand the underlying reason, we found that all these observations have tenure=0. We decided that the most appropriate option is to manually impute these TotalCharges with 0. If the tenure is 0, it implies that the contract has not started, indicating no debt or amount to be paid. 
We validated the imputation using density plots and confirmed that the distribution remained unchanged. Therefore, we proceeded with these imputed values.


```{r, missing_data}
#, fig.height=1.5

# Duplicates observations
df1 <- distinct(df1, .keep_all = TRUE)

# Numeric to factor SeniorCitizen
df1$SeniorCitizen <- df1$SeniorCitizen %>% as.factor()

# Take off the variable customerID
df1 <- subset(df1, select = -customerID)

cat_keep <- names(df1)[sapply(df1, function(x) is.character(x))]
numeric_columns <-  names(df1)[sapply(df1, function(x) is.numeric(x))]

df1[cat_keep] <- lapply(df1[cat_keep], as.factor) ## Create Factors
df1[numeric_columns] <- lapply(df1[numeric_columns], as.numeric)

# Missing values
plot_missing(df1, missing_only = TRUE, group = list("Low" = 0.05, "Medium"=0.25, "High"=0.5, "Very High" =1), geom_label_args = list("size" = 2))

observaciones_na <- df1 %>% filter(is.na(TotalCharges))
print(observaciones_na$tenure)

# Errors or inconsistencies -> imputed
df2 <- df1
df2$TotalCharges <- ifelse(is.na(df2$TotalCharges) & df2$tenure == 0, 0, df2$TotalCharges)

# validation
summary(df2$TotalCharges)
summary(df1$TotalCharges)
par(mfrow=c(1,2))
plot(density(df1$TotalCharges,na.rm=TRUE), main = "Density TotalCharges", 
     xlab = "TotalCharges", ylab = "Density")
plot(density(df2$TotalCharges,na.rm=TRUE), main = "Density Imputed TotalCharges", 
     xlab = "TotalCharges", ylab = "Density")

#inconsistencias con el No phone service o No internet service
summary(df2) # misma frec de no phone y internet service en las variables
```

# Variable analysis
## Categorical values
To analyze the categorical variables, we have depicted a barplot for each of them in the figure below. 

One of the most relevant observations is that our response variable, Churn, is unbalanced, with significantly more negative cases than positive ones.

```{r, categorical_plot}
p1 <- df2 %>% 
  select(all_of(cat_keep)) %>%
  pivot_longer(cols=everything()) %>%
  ggplot(data=.) +
  geom_bar(aes(x=value), col="black", fill="white") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~name, scales="free", ncol=4)
p1

```

## Numerical Data
In order to analyze the numerical variables, we have represented a boxplot for each of them in the figure below. Notably, none of them show univariate outliers.

Subsequently, we discretized each variable into four quartiles and represented them as factors. We displayed their frequency tables to verify that the data is appropriately distributed across each category.

```{r, num_graphs}
#, fig.height=20
p2 <- df2 %>% 
  select(all_of(numeric_columns)) %>%
  pivot_longer(cols=everything()) %>%
  ggplot(data=.) +
  geom_boxplot(aes(y=value), col="black", fill="white") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~name, scales="free", ncol=4)
p2

# Create a discretization of numeric variables
sm <- summary(df2$tenure)
df2$f.tenure <- ifelse(df2$tenure <= sm["1st Qu."], 1, 
               ifelse(df2$tenure > sm["1st Qu."] & df2$tenure <= sm["Mean"], 2,
               ifelse(df2$tenure > sm["Mean"] & df2$tenure <= sm["3rd Qu."], 3, 
               ifelse(df2$tenure > sm["3rd Qu."], 4,0))))
df2$f.tenure <- factor(df2$f.tenure, labels=c("LowTenure","LowMidTenure","HighMidTenure","HighTenure"), order = T, levels=c(1,2,3,4))
table(df2$f.tenure)

sm <- summary(df2$MonthlyCharges)
df2$f.MonthlyCharges <- ifelse(df2$MonthlyCharges <= sm["1st Qu."], 1, 
               ifelse(df2$MonthlyCharges > sm["1st Qu."] & df2$MonthlyCharges <= sm["Mean"], 2,
               ifelse(df2$MonthlyCharges > sm["Mean"] & df2$MonthlyCharges <= sm["3rd Qu."], 3, 
               ifelse(df2$MonthlyCharges > sm["3rd Qu."], 4,0))))
df2$f.MonthlyCharges <- factor(df2$f.MonthlyCharges, labels=c("LowMonthlyCharges","LowMidMonthlyCharges","HighMidMonthlyCharges","HighMonthlyCharges"), order = T, levels=c(1,2,3,4))
table(df2$f.MonthlyCharges)

sm <- summary(df2$TotalCharges)
df2$f.TotalCharges <- ifelse(df2$TotalCharges <= sm["1st Qu."], 1, 
               ifelse(df2$TotalCharges > sm["1st Qu."] & df2$TotalCharges <= sm["Mean"], 2,
               ifelse(df2$TotalCharges > sm["Mean"] & df2$TotalCharges <= sm["3rd Qu."], 3, 
               ifelse(df2$TotalCharges > sm["3rd Qu."], 4,0))))
df2$f.TotalCharges <- factor(df2$f.TotalCharges, labels=c("LowTotalCharges","LowMidTotalCharges","HighMidTotalCharges","HighTotalCharges"), order = T, levels=c(1,2,3,4))
table(df2$f.TotalCharges)
```
# Data Quality Report

## Multivariate outliers
In the initial analysis of multivariate outliers, a significance level of 0.05% was chosen as a very mild threshold. However, the vertical threshold is not visible on the graph as it extends beyond its limits. It is evident that there are no multivariate outliers beyond this threshold. We opted not to set a higher significance level because the observations are very grouped and there is no apparent clear outlier that warrants removal from the dataset.

```{r}
df_of_interest <- df2[,c(numeric_columns)]

res.out = Moutlier(df_of_interest, quantile = 0.9995, col="green") 

which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff))
length(which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff)))

par(mfrow=c(1,1))
plot( res.out$md, res.out$rd )
abline(h=res.out$cutoff, col="red")
abline(v=res.out$cutoff, col="red")

#summary(df2[which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff)),])
#summary(df2)

#df2 = df2[-which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff)),]
```

## Data Quality Report
As we have seen before, there are no univariate outliers, therefore, we have left the column empty, although it is represented to consider it as a parameter in the total quality sum. To measure missing values, we have conducted a column count, although we had already seen in the first section that the only column with missing values was TotalCharges, we have taken the values from the not imputed dataframe. Additionally, we consider it an error if the dataset has the tenure value equal to 0. Taking these metrics into account, we observe that the two variables with lower quality are tenure and TotalCharges. We do not believe it is necessary to look at another analysis per individuals to see the correlation with the variables because the two most related variables have been very explicitly identified in the analysis per variable.

### Per variable
```{r}
dq <- data.frame(colnames(df1[, 1:20]))
dq$outliers <- 0
dq$missing <- 0
dq$errors <- 0

dq$missing <- (colSums(is.na(df1[, 1:20])))
dq$errors[dq$colnames=="tenure"] <- sum(ifelse(df1$tenure == 0, 1, 0))
dq$quality <- dq$outliers + dq$missing + dq$errors
dq
``` 


# Profiling and Feature Selection

##  Interactions between the target and other variables
The results from FactoMinerR::catdes() show the relationship between the variable Churn and both categorical and quantitative variables.

For categorical variables, the chi-square test was used. The p-values for all variables are extremely small, indicating a significant association between these variables and the Churn variable. The variables with the strongest association are 'Contract', 'f.tenure', 'OnlineSecurity', and 'TechSupport', as they have the smallest p-values.

The variable Churn is also described by the categories. For the 'No' cluster, the categories with the highest v.test values (indicating a strong association) are 'Contract=Two year', 'f.tenure=HighTenure', and 'StreamingMovies=No internet service'. For the 'Yes' cluster, the categories with the highest v.test values are 'Contract=Month-to-month', 'OnlineSecurity=No', and 'TechSupport=No'.

For quantitative variables, the Eta2 statistic was used. The variable 'tenure' has the highest Eta2 value, indicating it has the strongest association with the cluster variable. The p-values for all variables are extremely small, indicating a significant association.

The variable Churn is also described by the quantitative variables. For the 'No' cluster, the variable with the highest v.test value (indicating a strong association) is 'tenure'. For the 'Yes' cluster, the variable with the highest v.test value is 'MonthlyCharges'.

As all variables are significant in relation with the variable Churn we will keep all of them at the moment. 
```{r}
catdes(df2, num.var=which(names(df2) == 'Churn'))
```

# Churn Modelling
## Modelling using numeric variables
Initially, we built a model using only the numerical variables in our dataset. Upon examining the initial model with the vif function, we observe that there exists a high correlation between Total Charges and tenure. We will keep tenure variable, because TotalCharges is the variable that is created from tenure, in order to simplify and exclude redundant variables. Subsequent vif analysis confirmed the actual absence of multicorrelation.

Exploring interactions between these two variables gave us insignificant differences, leading us to stay with the less complex model. We tried to exchange these numeric variables with its previously created factor variables were made, but judging by the AIC parameter, the numeric variables give us better results.

Moreover, some transformations were applied to the variables. While the logarithmic transformation produced bad outcomes, the polynomial transformation significantly improved the results for tenure, although not for MonthlyCharges. Based on these findings, we kept the current best performing model which is mod_num6.

Finally, we show the effect plots of the features in the best model, and we can observe that the fewer months you stay with the company (tenure), the more likely you are to leave the company (churn yes), and the same applies in the opposite direction. Instead, the fewer monthly charges you have (MonthlyCharges), the more likely you are to stay with the company (churn no), and again, the same applies in the opposite direction.

```{r}
set.seed(123)
rows <- sample(nrow(df2), .75 * nrow(df2))
train_new <- df2[rows, ]
test_new <- df2[-rows, ]

## Start with the numeric variables 

attach(train_new)
mod_num <- glm(Churn ~ tenure + TotalCharges + MonthlyCharges, family = "binomial", data=train_new )
vif(mod_num) ## We can see high correlation between Total Charges and tenure. We will keep tenure as it is the most important. 

mod_num2 <- glm(Churn ~ tenure + MonthlyCharges, family = "binomial", data=train_new )
vif(mod_num2) ## There is not multicorrelation 

# Let's check if interactions may be needed

mod_num3 <- glm(Churn ~ tenure*MonthlyCharges, family="binomial", data=train_new)
anova(mod_num2, mod_num3, test = "Chisq") # Not significant


mod_num2i <- glm(Churn ~ f.tenure + f.MonthlyCharges, family = "binomial", data=train_new )
AIC(mod_num2);AIC(mod_num2i) ## It is better with the numeric variables

mod_num4 <- glm(Churn ~ tenure + log(MonthlyCharges), family = binomial, data=train_new)
mod_num4


AIC(mod_num2);AIC(mod_num4) ## It is better without transformation


## Let's check for polynomial transformations
mod_num5 <- glm(Churn ~ poly(tenure,2) + poly(MonthlyCharges,2), family = binomial, data=train_new)
summary(mod_num5)
anova(mod_num2, mod_num5, test="Chisq") ## It is significant but MonthlyCharges is not significant


mod_num6 <- glm(Churn ~ poly(tenure,2) + MonthlyCharges, family = binomial, data=train_new)

anova(mod_num6, mod_num5, test="Chisq") ## We will keep model 6. We could try to make polynomial of higher degrees but would be complicated to understand. 

plot(allEffects( mod_num6 )) ## We can see how tenure slope is smoothed in high tenure. 

```

## Residual analysis

```{r}
residualPlots( mod_num6 )

## Looks pretty flat some observations in low Monthly charges have higher residuals but is not normal as the predictor has positive correlation, so low Monthly charges with churn are less probable. 

influencePlot( mod_num6 ) 
## There are some observations that have higher residuals than expected but are not very separate from each other. Let's check the boxplot

Boxplot(cooks.distance( mod_num6 ))

## We have some influential values but it just because it is rare of low Monthly Charges to have a churn. We believe we should keep them in the dataset in order to not manipulate too much the model and have biased results. 


```
## Adding factor main effects to the best model containing numeric variables 
As a last step to create our model, we introduced all our categorical variables to the model and we run step() to remove non significant predictors. 
There are multiple variables that are very related with the level No Internet these generate the model to not converge in some betas. As the levels in these variables can be also categorized as No instead of No Internet Service. Also we will be able to aisle the effect of No Internet with the variable InternetService. If more NA generate all the variance will be captured with the variable InternetService or other variable.

After refactoring all the variables that were related to each other we can see that MonthlyCharges is dependent on some of the other variables. We will remove those which are not significant and check whether we should add them or not. With the anova test we can observe that the change is not significant so we can keep the small model with the principle of parsimony. Through the vif we can also see that the multicorrelation has reduced.

Finally, we show the effect plots of the features in the model so we are able to define which category of Churn is more likely to happen when the feature takes the different values.

```{r}
#train_new
mod <- glm(Churn ~ gender + SeniorCitizen +  Partner + Dependents + poly(tenure, 2) + MultipleLines + InternetService + OnlineSecurity + OnlineBackup + DeviceProtection + TechSupport + StreamingTV + StreamingMovies + Contract + PaperlessBilling + MonthlyCharges, data=train_new, family = binomial)
summary(mod)
step_mod <- step(mod, trace=F)
summary(step_mod) ## There are multiple variables that are very related with the level No Internet these generate the model to not converge in some betas. As the levels in these variables can be also categorized as No instead of No Internet Service. Also we will be able to aisle the effect of No Internet with the variable InternetService. If more NA generate all the variance will be captured with the variable InternetService or other variable. 

train_new$OnlineBackup    <- train_new$OnlineBackup    %>% as.character()
train_new$OnlineSecurity    <- train_new$OnlineSecurity    %>% as.character()
train_new$DeviceProtection<- train_new$DeviceProtection %>% as.character()
train_new$TechSupport     <- train_new$TechSupport     %>% as.character()
train_new$StreamingTV     <- train_new$StreamingTV     %>% as.character()
train_new$StreamingMovies <- train_new$StreamingMovies %>% as.character()

train_new$OnlineBackup     <- ifelse(train_new$OnlineBackup == 'No internet service', 'No', train_new$OnlineBackup)
train_new$OnlineSecurity     <- ifelse(train_new$OnlineSecurity == 'No internet service', 'No', train_new$OnlineSecurity)
train_new$DeviceProtection <- ifelse(train_new$DeviceProtection == 'No internet service', 'No', train_new$DeviceProtection)
train_new$TechSupport      <- ifelse(train_new$TechSupport == 'No internet service', 'No', train_new$TechSupport)
train_new$StreamingTV      <- ifelse(train_new$StreamingTV == 'No internet service', 'No', train_new$StreamingTV)
train_new$StreamingMovies  <- ifelse(train_new$StreamingMovies == 'No internet service', 'No', train_new$StreamingTV)

train_new$OnlineBackup    <- train_new$OnlineBackup    %>% as.factor()
train_new$OnlineSecurity    <- train_new$OnlineSecurity    %>% as.factor()
train_new$DeviceProtection<- train_new$DeviceProtection %>% as.factor()
train_new$TechSupport     <- train_new$TechSupport     %>% as.factor()
train_new$StreamingTV     <- train_new$StreamingTV     %>% as.factor()
train_new$StreamingMovies <- train_new$StreamingMovies %>% as.factor()


mod2 <- glm(Churn ~ gender + SeniorCitizen +  Partner + Dependents + poly(tenure, 2) + MultipleLines + InternetService + OnlineSecurity + OnlineBackup + DeviceProtection + TechSupport + StreamingTV + Contract + PaperlessBilling + MonthlyCharges, data=train_new, family = binomial)

summary(mod2)
vif(mod2)
## After refactoring all the variables that were related to each other we can see that MonthlyCharges is dependent on some of the other variables. We will remove those which are not significant and check whether we should add them or not.


Anova(mod2, test="LR")

mod3 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + MultipleLines + OnlineSecurity + OnlineBackup + TechSupport + Contract + PaperlessBilling + MonthlyCharges, data=train_new, family = binomial)
Anova(mod3, test="LR")

anova(mod3, mod2, test="Chisq") ## It is not significant so we can keep the small model with the principle of parsimony. 

vif(mod3) ## The multicorrelation has reduced.

plot(allEffects(mod3))


```

## Residual analysis with categorical variables


```{r}

residualPlots(mod3)
influencePlot(mod3)
cook <- Boxplot(cooks.distance(mod3))
cookd <- sort(cooks.distance(mod3)[cook], decreasing=TRUE)
cookd
length(rownames(train_new) %in% names(cookd)) #[1] 5282

```


## Factor interactions
Now, we are searching for interactions between factors in the model, beginning by testing some combinations of variables that had sense for us to have relation between them. We identify the one that yields the best results. But, given the high quantity of variables, manually exploring combinations becomes impractical. Hence, we employ the iterative stepwise method to check different combinations. The iteration providing the best results includes interactions between OnlineSecurity and TechSupport with a high representation, and MultipleLines and TechSupport with minimal representation. We tested the one with more representation alone, and then with both interactions to assess any significant improvement. However, there is no significant change observed, leading us to choose the simpler model, mod7.
 
```{r}

mod4 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + MultipleLines + OnlineSecurity + OnlineBackup + TechSupport + Contract * PaperlessBilling + MonthlyCharges, data=train_new, family = binomial)

anova(mod3, mod4, test="Chisq")

mod5 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + (MultipleLines + OnlineSecurity + OnlineBackup + TechSupport)*MonthlyCharges + Contract + PaperlessBilling, data=train_new, family = binomial)

anova(mod3, mod5, test="Chisq")

mod6 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + (MultipleLines + OnlineSecurity + OnlineBackup + TechSupport + MonthlyCharges)^2 + Contract + PaperlessBilling, data=train_new, family = binomial)

step_mod <- step(mod6, trace=F) # muchas variables como para ver sus combinaciones por eso utilizamos el metodo iterativo stepwise
summary(step_mod)

mod7 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + MultipleLines + OnlineSecurity*TechSupport + OnlineBackup + MonthlyCharges + Contract + PaperlessBilling, data=train_new, family = binomial)

anova(mod3, mod7, test="Chisq")

mod8 <- glm(Churn ~ SeniorCitizen +  poly(tenure, 2) + (MultipleLines + OnlineSecurity)*TechSupport + OnlineBackup + MonthlyCharges + Contract + PaperlessBilling, data=train_new, family = binomial)

anova(mod7, mod8, test="Chisq") # no cambio significant, nos quedamos con el simple mod7


```



## Residual analysis with the best model

```{r}

residualPlots(mod7)
influencePlot(mod7)
cook <- Boxplot(cooks.distance(mod7))
cookd <- sort(cooks.distance(mod7)[cook], decreasing=TRUE)
cookd
length(rownames(train_new) %in% names(cookd)) #[1] 5282

```


## Model Interpretation and residual analysis

```{r}
summary(mod7)
vif(mod7)
exp(mod7$coefficients) 

par(mfrow=c(1,2))
plot(allEffects(mod = mod7))
#avPlots(mod7) #es como el effect
sum( resid( mod7, "pearson") ^2 )

residualPlots(mod7)

```
The final model has this form.

$$
\begin{align*}
y = & -3.1427 \alpha + \beta_{\text{SeniorCitizen1}} 0.26 + \beta_{\text{tenure}} (-50.09) + \beta_{\text{tenure}^2} 23.85 \\
& + \beta_{\text{MultipleLinesNo phone service}} 1.16 + \beta_{\text{MultipleLinesYes}} 0.14 + \beta_{\text{OnlineSecurityYes}} (-0.68) \\
& + \beta_{\text{TechSupportYes}} (-0.64) + \beta_{\text{OnlineBackupYes}} (-0.32) + \beta_{\text{MonthlyCharges}} 0.03 \\
& + \beta_{\text{ContractOne year}} (-0.81) + \beta_{\text{ContractTwo year}} (-2.15) + \beta_{\text{PaperlessBillingYes}} 0.35 \\
& + \beta_{\text{OnlineSecurityYes:TechSupportYes}} 0.47
\end{align*}
$$

From the effects plots and the betas we can draw the following conclusions:

 - Senior Citizen are more likely to Churn than no Senior Citizens as the have an odds of 1.3 against non senior citizens.
 - We can understand tenure very easily thanks to the plot of effects. We can see how old clients of the company (old in terms of months in the company) are less probable to live the company although it smoothes this behaviour as the client reaches 40 months, this is a very important variable in order to explain churns. 
 - Those clients who don't have a phone service have an odds of 3.2 for leaving compared to those who only have 1 line.
 - The clients who have Online Backup are less likely to live the company, with an odds of 0.72 compared to those who have not. 
 - Monthly charges has a linear relation with the probability of Churn, in other words, the probability of leaving is higher as the Montly Charges become higher. The odds of leaving for every unit of Monthly Charges is 1.0344. This is also a very important variable in our model. 
 - Those clients which have a shorter contract effect are more prone to leave than the others. We can see how the odds of leaving for Two year effect contracts is 0.11 compared to Month-to-Month. So the probability of leaving for those who have month-to-month contract are 9 times higher. 
 - Paperless Billing has also an effect with an odds ratio of 1.42 of yes against no.
 - Lastly we can check the effect of the interaction between Online Security and Tech Support. If the client has Tech Support will be less likely to leave, otherwise will be more likely to leave, especially if she/he has not Online Security either. 

Residual analysis:

We can see the effects on having an unbalanced dataset in our residual/Goodness of fit analysis.  We can interpret from the plots that our residuals are far more likely to have extreme positive values rather than negative ones. In fact they are very related to the conclusions of the model interpretation. As the combination of variables gets more prone to not churn we will see more influential values in the positive axis. 





### Standarize test

```{r}
test_new$OnlineBackup    <- test_new$OnlineBackup    %>% as.character()
test_new$OnlineSecurity    <- test_new$OnlineSecurity    %>% as.character()
test_new$DeviceProtection<- test_new$DeviceProtection %>% as.character()
test_new$TechSupport     <- test_new$TechSupport     %>% as.character()
test_new$StreamingTV     <- test_new$StreamingTV     %>% as.character()
test_new$StreamingMovies <- test_new$StreamingMovies %>% as.character()

test_new$OnlineBackup     <- ifelse(test_new$OnlineBackup == 'No internet service', 'No', test_new$OnlineBackup)
test_new$OnlineSecurity     <- ifelse(test_new$OnlineSecurity == 'No internet service', 'No', test_new$OnlineSecurity)
test_new$DeviceProtection <- ifelse(test_new$DeviceProtection == 'No internet service', 'No', test_new$DeviceProtection)
test_new$TechSupport      <- ifelse(test_new$TechSupport == 'No internet service', 'No', test_new$TechSupport)
test_new$StreamingTV      <- ifelse(test_new$StreamingTV == 'No internet service', 'No', test_new$StreamingTV)
test_new$StreamingMovies  <- ifelse(test_new$StreamingMovies == 'No internet service', 'No', test_new$StreamingTV)

test_new$OnlineBackup    <- test_new$OnlineBackup    %>% as.factor()
test_new$OnlineSecurity    <- test_new$OnlineSecurity    %>% as.factor()
test_new$DeviceProtection<- test_new$DeviceProtection %>% as.factor()
test_new$TechSupport     <- test_new$TechSupport     %>% as.factor()
test_new$StreamingTV     <- test_new$StreamingTV     %>% as.factor()
test_new$StreamingMovies <- test_new$StreamingMovies %>% as.factor()
```

### Goodness of fit 

```{r}
final_model <- mod7
dim(test_new)
predictions <- predict(final_model,test_new, type="response")
test_new$PredictedChurn <- ifelse(predictions > 0.5,"Yes","No") %>% as.factor
val <- table(test_new$PredictedChurn, test_new$Churn)

val %>% knitr::kable()
accuracy <- sum(diag(val))/sum(val)
TP <- val[2,2]
FN <- val[1,2]
FP <- val[2,1]

accuracy <- sum(diag(val))/sum(val)
Recall <- TP/(TP+FN)
Precision <- TP / (TP + FP)
F1 <- 2 * (Precision * Recall) / (Precision + Recall)

GOF <- rbind(accuracy, Recall, Precision, F1)
colnames(GOF) <- "Metrics"
GOF %>% round(2) %>% knitr::kable()



library("ROCR")
dadesroc<-prediction(predict(final_model, newdata = test_new,type="response"),test_new$Churn)
par(mfrow=c(1,2))
plot(performance(dadesroc,"err"))
plot(performance(dadesroc,"tpr","fpr"))
abline(0,1,lty=2)


predictions <- predict(final_model,test_new, type="response")
test_new$PredictedChurn <- ifelse(predictions > 0.4,"Yes","No") %>% as.factor
val <- table(test_new$PredictedChurn, test_new$Churn)

table(test_new$PredictedChurn)
table(test_new$Churn)
TP <- val[2,2]
FN <- val[1,2]
FP <- val[2,1]

accuracy <- sum(diag(val))/sum(val)
Recall <- TP/(TP+FN)
Precision <- TP / (TP + FP)
F1 <- 2 * (Precision * Recall) / (Precision + Recall)

GOF <- rbind(accuracy, Recall, Precision, F1)
colnames(GOF) <- "Metrics"
GOF %>% round(2) %>% knitr::kable()
 ## F1 improves so we will keep the second threshold
```

We utilized 20% of our data to establish the goodness of fit, applying the final model to predict churn within our test set. Subsequently, we applied a 0.5 threshold, obtaining an accuracy of 0.83. Notwithstanding the semblance of a good fit, misleading interpretations could arise due to an imbalanced dataset. 

Exploration of the metrics table highlights a F1 score of 0.62 and a recall of 0.57, providing a clearer picture. It led us to the decision of changing the threshold to 0.4 based on the Receiver Operating Characteristic (ROC) curve. Despite a minor decrease in accuracy to 0.81, we noted an improvement in the F1 score to 0.64 and a significant increase in recall (0.68). We consider this shift important because the company is more concerned about false positives since they have a greater impact on the business than false negatives.



